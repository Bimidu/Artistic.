# Project Structure

Complete file structure and organization for the ASD Detection system.

## ğŸ“ Directory Tree

```
Artistic./
â”‚
â”œâ”€â”€ ğŸ“„ config.py                          # Central configuration management
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                         # Main documentation
â”œâ”€â”€ ğŸ“„ QUICK_START.md                    # Quick start guide
â”œâ”€â”€ ğŸ“„ IMPLEMENTATION_SUMMARY.md         # Technical implementation details
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md              # This file
â”‚
â”œâ”€â”€ ğŸ“‚ data/                             # Dataset directory (user provided)
â”‚   â”œâ”€â”€ asdbank_aac/                     # 18 ASD children (minimally speaking)
â”‚   â”œâ”€â”€ asdbank_eigsti/                  # 16 ASD + 16 TD + 16 DD
â”‚   â”œâ”€â”€ asdbank_flusberg/                # 6 ASD (longitudinal)
â”‚   â”œâ”€â”€ asdbank_nadig/                   # 20 ASD + 18 TYP
â”‚   â”œâ”€â”€ asdbank_quigley_mcnalley/       # 105 HR + 98 LR
â”‚   â””â”€â”€ asdbank_rollins/                 # 5 ASD
â”‚
â”œâ”€â”€ ğŸ“‚ src/                              # Source code
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ parsers/                      # PHASE 1: Data Parsing
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ chat_parser.py           # CHAT file parsing (470 lines)
â”‚   â”‚   â””â”€â”€ ğŸ“„ dataset_inventory.py     # Dataset management (424 lines)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ features/                     # PHASE 2: Feature Extraction
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ base_features.py         # Base classes & utilities
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ feature_extractor.py     # Main orchestrator
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ”µ CATEGORY 1: ACOUSTIC & PROSODIC (Team Member A)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ acoustic_prosodic/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ acoustic_prosodic.py # Acoustic features (12)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ”µ CATEGORY 2: SYNTACTIC & SEMANTIC (Team Member B)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ syntactic_semantic/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ syntactic_semantic.py # Syntactic features (12)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸŸ¢ CATEGORY 3: PRAGMATIC & CONVERSATIONAL (Implemented)
â”‚   â”‚       â”œâ”€â”€ ğŸ“‚ pragmatic_conversational/
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“„ turn_taking.py   # Turn-taking features (15)
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“„ linguistic.py    # Linguistic features (14)
â”‚   â”‚       â”‚   â”œâ”€â”€ ğŸ“„ pragmatic.py     # Pragmatic features (16)
â”‚   â”‚       â”‚   â””â”€â”€ ğŸ“„ conversational.py # Conversational features (16)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ utils/                        # Utility functions
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ logger.py                # Logging configuration
â”‚       â””â”€â”€ ğŸ“„ helpers.py               # Helper functions
â”‚
â”œâ”€â”€ ğŸ“‚ examples/                         # Usage examples
â”‚   â””â”€â”€ ğŸ“„ example_usage.py             # Comprehensive examples
â”‚
â”œâ”€â”€ ğŸ“‚ output/                          # Generated outputs
â”‚   â”œâ”€â”€ inventory.csv                   # Dataset inventory
â”‚   â”œâ”€â”€ features.csv                    # Extracted features
â”‚   â””â”€â”€ *.csv                           # Analysis results
â”‚
â”œâ”€â”€ ğŸ“‚ models/                          # ML models (Phase 3)
â”‚   â””â”€â”€ (to be implemented)
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                            # Log files
â”‚   â””â”€â”€ asd_detection.log              # Application logs
â”‚
â””â”€â”€ ğŸ“‚ cache/                           # Cached data
    â””â”€â”€ inventory.json                  # Cached inventory
```

## ğŸ”§ Core Modules

### 1. Configuration (`config.py`)

```python
PathConfig          # File paths and directories
FeatureConfig       # Feature extraction parameters
ProcessingConfig    # System settings
LoggingConfig       # Logging configuration
DatasetConfig       # Dataset mappings
```

### 2. Parsers (`src/parsers/`)

#### `chat_parser.py`
```python
CHATParser          # Main parser class
  â”œâ”€â”€ parse_file()                    # Parse single .cha file
  â”œâ”€â”€ parse_directory()               # Batch parsing
  â””â”€â”€ _extract_metadata()             # Metadata extraction

TranscriptData      # Parsed transcript container
  â”œâ”€â”€ participant_id                  # Participant identifier
  â”œâ”€â”€ diagnosis                       # Clinical diagnosis
  â”œâ”€â”€ age_months                      # Age in months
  â”œâ”€â”€ utterances                      # All utterances
  â””â”€â”€ speakers                        # Speaker information

Utterance          # Single utterance representation
  â”œâ”€â”€ speaker                         # Speaker code (CHI, MOT, INV)
  â”œâ”€â”€ text                           # Utterance text
  â”œâ”€â”€ tokens                         # Word tokens
  â”œâ”€â”€ morphology                     # POS/morphology (%mor)
  â”œâ”€â”€ grammar                        # Grammar relations (%gra)
  â”œâ”€â”€ timing                         # Timestamp
  â”œâ”€â”€ actions                        # Actions (%act)
  â””â”€â”€ comments                       # Comments (%com)
```

#### `dataset_inventory.py`
```python
DatasetInventory    # Dataset management
  â”œâ”€â”€ build_inventory()              # Build complete inventory
  â”œâ”€â”€ get_participants_by_diagnosis() # Filter by diagnosis
  â”œâ”€â”€ get_dataset_summary()          # Get statistics
  â”œâ”€â”€ to_dataframe()                 # Export to DataFrame
  â””â”€â”€ export_to_csv()                # Save to CSV

ParticipantInfo     # Participant metadata
  â”œâ”€â”€ participant_id
  â”œâ”€â”€ dataset
  â”œâ”€â”€ diagnosis
  â”œâ”€â”€ age_months
  â”œâ”€â”€ num_sessions
  â””â”€â”€ total_utterances
```

### 3. Features (`src/features/`)

#### Architecture
```
BaseFeatureExtractor (Abstract)
  â”œâ”€â”€ extract()                      # Main extraction method
  â”œâ”€â”€ feature_names                  # List of features
  â””â”€â”€ utility methods

Category 1: Acoustic & Prosodic (Placeholder)
  â””â”€â”€ AcousticProsodicFeatures
      â””â”€â”€ 12 features (pitch, rate, prosody, pauses)

Category 2: Syntactic & Semantic (Placeholder)
  â””â”€â”€ SyntacticSemanticFeatures
      â””â”€â”€ 12 features (syntax, grammar, semantics)

Category 3: Pragmatic & Conversational (âœ… Implemented)
  â”œâ”€â”€ TurnTakingFeatures
  â”‚   â””â”€â”€ 15 features
  â”œâ”€â”€ LinguisticFeatures
  â”‚   â””â”€â”€ 14 features
  â”œâ”€â”€ PragmaticFeatures
  â”‚   â””â”€â”€ 16 features
  â””â”€â”€ ConversationalFeatures
      â””â”€â”€ 16 features
```

#### Main Orchestrator
```python
FeatureExtractor    # Coordinates all extractors
  â”œâ”€â”€ extract_from_transcript()      # Single transcript
  â”œâ”€â”€ extract_from_files()           # Batch processing
  â”œâ”€â”€ extract_from_directory()       # Directory processing
  â”œâ”€â”€ normalize_features()           # Feature normalization
  â”œâ”€â”€ get_feature_summary()          # Statistics
  â””â”€â”€ print_category_info()          # Display info

FeatureSet         # Feature container
  â”œâ”€â”€ participant_id
  â”œâ”€â”€ diagnosis
  â”œâ”€â”€ features                       # Dict of features
  â””â”€â”€ metadata
```

### 4. Utilities (`src/utils/`)

```python
# logger.py
setup_logger()      # Configure logging
get_logger()        # Get logger instance

# helpers.py
timing_decorator    # Time function execution
safe_divide()       # Safe division
calculate_ratio()   # Calculate ratios
normalize_text()    # Text normalization
is_valid_utterance() # Utterance validation
extract_timing_info() # Parse timing
get_age_in_months() # Parse age
```

## ğŸ“Š Feature Categories

### Category 3: Pragmatic & Conversational (61 features) âœ…

#### Turn-Taking (15 features)
```
total_turns
child_turns
adult_turns
turns_per_minute
child_turn_ratio
avg_turn_length_words
avg_child_turn_length
avg_adult_turn_length
avg_response_latency
median_response_latency
child_initiated_turns
adult_initiated_turns
child_initiation_ratio
turn_switches
avg_turns_before_switch
```

#### Linguistic (14 features)
```
mlu_words
mlu_morphemes
avg_word_length
max_utterance_length
total_words
unique_words
type_token_ratio
corrected_ttr
noun_ratio
verb_ratio
adjective_ratio
pronoun_ratio
function_word_ratio
lexical_density
utterance_complexity_score
```

#### Pragmatic (16 features)
```
echolalia_ratio
immediate_echolalia_count
delayed_echolalia_count
partial_repetition_ratio
question_ratio
question_diversity
yes_no_question_ratio
wh_question_ratio
pronoun_usage_ratio
first_person_pronoun_ratio
pronoun_error_ratio
pronoun_reversal_count
social_phrase_ratio
greeting_count
politeness_marker_count
appropriate_response_ratio
unintelligible_ratio
```

#### Conversational (16 features)
```
topic_shift_ratio
topic_maintenance_score
topic_intro_marker_ratio
avg_topic_duration
discourse_marker_ratio
continuation_marker_ratio
repair_marker_ratio
acknowledgment_ratio
self_repair_count
other_repair_count
clarification_request_ratio
nonverbal_behavior_ratio
laughter_ratio
vocal_behavior_diversity
topic_relevance_score
off_topic_ratio
```

### Category 1: Acoustic & Prosodic (12 features) ğŸ”µ
```
mean_pitch
pitch_std
pitch_range
pitch_slope
speaking_rate
articulation_rate
pause_rate
intonation_variability
stress_pattern_score
rhythm_score
mean_pause_duration
filled_pause_ratio
```
**Status**: Placeholder for Team Member A

### Category 2: Syntactic & Semantic (12 features) ğŸ”µ
```
avg_dependency_depth
max_dependency_depth
clause_complexity
subordination_index
grammatical_error_rate
tense_consistency_score
agreement_error_rate
structure_diversity
semantic_coherence
semantic_density
thematic_consistency
vocabulary_abstractness
semantic_role_diversity
word_sense_accuracy
```
**Status**: Placeholder for Team Member B

## ğŸ“ˆ Data Flow

```
1. DATA INPUT
   â””â”€> .cha files (CHAT format)

2. PHASE 1: PARSING
   â””â”€> CHATParser
       â”œâ”€> Extract metadata
       â”œâ”€> Parse utterances
       â”œâ”€> Extract morphology/grammar
       â””â”€> TranscriptData object

3. DATASET INVENTORY
   â””â”€> DatasetInventory
       â”œâ”€> Scan all files
       â”œâ”€> Aggregate by participant
       â”œâ”€> Cache results
       â””â”€> Export CSV/JSON

4. PHASE 2: FEATURE EXTRACTION
   â””â”€> FeatureExtractor
       â”œâ”€> Turn-taking features
       â”œâ”€> Linguistic features
       â”œâ”€> Pragmatic features
       â”œâ”€> Conversational features
       â””â”€> FeatureSet object

5. OUTPUT
   â”œâ”€> CSV files (features.csv)
   â”œâ”€> Summary statistics
   â””â”€> Normalized features

6. PHASE 3 (Future)
   â””â”€> Machine Learning
       â”œâ”€> Model training
       â”œâ”€> Evaluation
       â””â”€> Prediction API
```

## ğŸ”„ Workflow Examples

### Workflow 1: Single File Analysis
```
.cha file â†’ CHATParser â†’ TranscriptData â†’ FeatureExtractor â†’ FeatureSet â†’ Analysis
```

### Workflow 2: Batch Processing
```
Directory â†’ CHATParser (batch) â†’ Multiple TranscriptData â†’ FeatureExtractor â†’ DataFrame â†’ CSV
```

### Workflow 3: Complete Pipeline
```
Raw Data â†’ Inventory â†’ Filter â†’ Parse â†’ Extract Features â†’ Normalize â†’ ML Ready
```

## ğŸ“ File Relationships

```
config.py
  â””â”€> Used by: All modules

src/utils/
  â”œâ”€> logger.py
  â”‚   â””â”€> Used by: All modules
  â””â”€> helpers.py
      â””â”€> Used by: parsers/, features/

src/parsers/
  â”œâ”€> chat_parser.py
  â”‚   â””â”€> Uses: utils/helpers, utils/logger
  â””â”€> dataset_inventory.py
      â””â”€> Uses: chat_parser, utils/logger

src/features/
  â”œâ”€> base_features.py
  â”‚   â””â”€> Uses: parsers/chat_parser, utils/
  â”œâ”€> turn_taking.py
  â”‚   â””â”€> Extends: base_features
  â”œâ”€> linguistic.py
  â”‚   â””â”€> Extends: base_features
  â”œâ”€> pragmatic.py
  â”‚   â””â”€> Extends: base_features
  â”œâ”€> conversational.py
  â”‚   â””â”€> Extends: base_features
  â””â”€> feature_extractor.py
      â””â”€> Coordinates: All feature extractors
```

## ğŸ¯ Entry Points

### For Users
```python
# Main entry point
examples/example_usage.py

# Quick test
python -c "from src.parsers.chat_parser import CHATParser; print('âœ“ System ready')"
```

### For Developers
```python
# Parser development
src/parsers/chat_parser.py

# Feature development
src/features/[module].py

# Configuration
config.py
```

### For Team Integration
```python
# Team Member A (Acoustic/Prosodic)
src/features/acoustic_prosodic.py

# Team Member B (Syntactic/Semantic)
src/features/syntactic_semantic.py
```

## ğŸ“¦ Dependencies

### Core
- pylangacq (CHAT parsing)
- pandas (data manipulation)
- numpy (numerical computing)

### Utilities
- tqdm (progress bars)
- loguru (logging)
- python-dotenv (configuration)

### Future (Team Integration)
- librosa (Team A - audio)
- spacy (Team B - NLP)

## ğŸ” Configuration Files

```
config.py          # Main configuration
.env              # Environment variables (optional)
.env.example      # Example configuration
```

## ğŸ“Š Output Files

```
output/
  â”œâ”€â”€ inventory.csv              # Dataset inventory
  â”œâ”€â”€ features.csv               # Extracted features
  â”œâ”€â”€ asd_features.csv          # ASD group features
  â”œâ”€â”€ td_features.csv           # TD group features
  â””â”€â”€ asd_vs_td_comparison.csv  # Comparison results

cache/
  â””â”€â”€ inventory.json            # Cached inventory

logs/
  â””â”€â”€ asd_detection.log         # Application logs
```

## ğŸ“ Learning Path

1. **Start Here**: `QUICK_START.md`
2. **Understand System**: `README.md`
3. **Technical Details**: `IMPLEMENTATION_SUMMARY.md`
4. **Code Structure**: `PROJECT_STRUCTURE.md` (this file)
5. **Try Examples**: `examples/example_usage.py`
6. **Integrate**: Follow integration guides

---

**Total Lines of Code**: ~3,500+
**Total Features**: 61 (implemented) + 24 (placeholders)
**Documentation**: 5 comprehensive guides
**Examples**: Multiple usage scenarios

